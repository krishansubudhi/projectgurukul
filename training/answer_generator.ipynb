{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'projectgurukul.prompt_templates' from '/Users/krishansubudhi/repos/projectgurukul/projectgurukul/prompt_templates.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from projectgurukul import scriptures, corelib, prompt_templates\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "from llama_index.llms import ChatMessage, MessageRole\n",
    "from llama_index.prompts import ChatPromptTemplate\n",
    "from llama_index.schema import MetadataMode\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.response.notebook_utils import display_response\n",
    "# apply nested async to run in a notebook\n",
    "import nest_asyncio\n",
    "import llama_index\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from llama_index import QueryBundle\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import importlib\n",
    "importlib.reload(prompt_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Split</th>\n",
       "      <th>Scripture</th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Question Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>Why does Vasishta refuse to give Sabala to Vis...</td>\n",
       "      <td>Context 1\\nहैरण्यानां रथानां च श्वेताश्वानां च...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>Did Hanuman's devotion to Rama ever waver, eve...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>What drove Ravana to kidnap Sita, and was it s...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>Describe Bharata's character and his approach ...</td>\n",
       "      <td>Context 1\\nश्वस्तु गन्तासि तं देशं वसाद्य सह म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>How did Ravana react upon learning about Dhumr...</td>\n",
       "      <td>Context 1\\n[Ravana comes to know that Rama and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Split Scripture      Category  \\\n",
       "0   1  Train  Ramayana  From Context   \n",
       "1   2  Train  Ramayana  From Context   \n",
       "2   3  Train  Ramayana  From Context   \n",
       "3   4  Train  Ramayana  From Context   \n",
       "4   5  Train  Ramayana  From Context   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Why does Vasishta refuse to give Sabala to Vis...   \n",
       "1  Did Hanuman's devotion to Rama ever waver, eve...   \n",
       "2  What drove Ravana to kidnap Sita, and was it s...   \n",
       "3  Describe Bharata's character and his approach ...   \n",
       "4  How did Ravana react upon learning about Dhumr...   \n",
       "\n",
       "                                    Question Context  \n",
       "0  Context 1\\nहैरण्यानां रथानां च श्वेताश्वानां च...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  Context 1\\nश्वस्तु गन्तासि तं देशं वसाद्य सह म...  \n",
       "4  Context 1\\n[Ravana comes to know that Rama and...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(\"~/Downloads/Gurukul Data - data_train.csv\").dropna(how = \"all\", axis = 1).fillna(\"\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using openAI models\n"
     ]
    }
   ],
   "source": [
    "retriever = corelib.get_fusion_retriever(['gita','ramayana'], is_offline=False, data_dir=\"../data/\")\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever,\n",
    "    text_qa_template = prompt_templates.custom_text_qa_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_service_context = ServiceContext.from_defaults(\n",
    "    llm = OpenAI(model = \"gpt-4-1106-preview\")\n",
    ")\n",
    "\n",
    "trained_model_service_context = ServiceContext.from_defaults(\n",
    "    llm = OpenAI(model = \"ft:gpt-3.5-turbo-1106:macro-mate::8jTl73oZ\")\n",
    ")\n",
    "\n",
    "query_engine_gpt_4 = RetrieverQueryEngine.from_args(\n",
    "    retriever,\n",
    "    text_qa_template = prompt_templates.custom_text_qa_template,\n",
    "    service_context=gpt4_service_context\n",
    ")\n",
    "\n",
    "query_engine_trained_model = RetrieverQueryEngine.from_args(\n",
    "    retriever,\n",
    "    text_qa_template = prompt_templates.training_text_qa_template,\n",
    "    service_context=trained_model_service_context\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import sys\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine_trained_model.query(\"Why bibhishana betray ravana?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_engine_trained_model.query(\"Why Lakshmana betray ravana?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(query_str, context_str):\n",
    "    prompt = prompt_templates.custom_text_qa_template.format_messages(\n",
    "        query_str = query_str,context_str= context_str)\n",
    "    return (llama_index.llms.openai_utils.to_openai_message_dicts(prompt))\n",
    "\n",
    "def get_prompt_str(query_str, context_str):\n",
    "    prompt = prompt_templates.custom_text_qa_template.format(\n",
    "        query_str = query_str,context_str= context_str)\n",
    "    return prompt\n",
    "\n",
    "def get_contexts(context_str):\n",
    "    # Define a regex pattern to match lines with \"Context\" labels\n",
    "    pattern = re.compile(r'Context \\d+')\n",
    "\n",
    "    # Use re.sub to replace matched lines with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', context_str)\n",
    "\n",
    "    # Split the text into contexts using '---' as a separator\n",
    "    contexts = [context.strip() for context in cleaned_text.split('---')]\n",
    "    return contexts\n",
    "\n",
    "def get_response(query, contexts ):\n",
    "    response = query_engine._response_synthesizer.get_response(\n",
    "        query,\n",
    "        contexts\n",
    "    )\n",
    "    #query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "def get_response_from_row(row):\n",
    "    query_str = row.Question\n",
    "    contexts = json.loads(row.used_context)\n",
    "    return get_response(query_str, contexts)\n",
    "\n",
    "def get_gpt4_response(query, contexts ):\n",
    "    response = query_engine_gpt_4._response_synthesizer.get_response(\n",
    "        query,\n",
    "        contexts\n",
    "    )\n",
    "    #query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "def get_trained_model_response(query, contexts ):\n",
    "    response = query_engine_trained_model._response_synthesizer.get_response(\n",
    "        query,\n",
    "        contexts\n",
    "    )\n",
    "    #query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "def process_row(row):\n",
    "    new_row = pd.Series(row)\n",
    "    try:\n",
    "        query_str = row.Question\n",
    "        if row.Category == \"Outside Context\":\n",
    "            contexts = get_contexts(row[\"Question Context\"])\n",
    "        else:\n",
    "            contexts = [result.get_content(metadata_mode=MetadataMode.LLM) for result in retriever.retrieve(query_str)]\n",
    "        context_str = \"\\n\\n\".join(contexts)\n",
    "        new_row[\"used_context\"] = json.dumps(contexts, ensure_ascii=False)\n",
    "        new_row[\"prompt_str\"] = get_prompt_str(query_str, context_str)\n",
    "        new_row[\"prompt_openai\"] = json.dumps(get_prompt(query_str, context_str), ensure_ascii=False)\n",
    "        # new_row[\"answer_gpt3\"] = get_response(query_str, contexts)\n",
    "        return new_row\n",
    "    except:\n",
    "        return new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed = data.progress_apply(process_row, axis = 1)\n",
    "# processed.to_csv(\"data_inferred.csv\", index=False, encoding = 'utf-8')\n",
    "# processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.read_csv(\"~/Downloads/Gurukul Data - data_labelled.csv\")\n",
    "# gpt3_responses = processed_data.iloc[10:].progress_apply(get_response_from_row, axis = 1)\n",
    "# gpt3_responses.to_frame(name='gpt3_responses').to_csv(\"gpt3_responses.csv\",encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Was Rama's decision to send Sita to the forest justified, considering the rumors about her purity?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.iloc[53].Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rama and Sugriva, along with their army of Vanaras, crossed the ocean to reach Lanka by building a bridge with the help of the Vanara army.\n",
      "\n",
      "In the Yuddha Kanda, Sarga 22 of the Valmiki Ramayana, it is described how the Vanaras, under the leadership of Nala, constructed the bridge:\n",
      "\n",
      "> तानि कोटि सहस्राणि वानराणां महौजसाम् ।  \n",
      "> बध्नन्तः सागरे सेतुं जुग्मुः पारं महोदधेः ।। 6.22.77 ।।  \n",
      "> \"The glorious Vanaras in thousands of crores reached the other side of the sea from the bridge constructed in the great sea.\"\n",
      "\n",
      "The bridge was described as:\n",
      "\n",
      "> विशालः सुकृतश्रशीमान् सुभूमिः सुसमाहितः ।  \n",
      "> अशोभत महान् सेतुः सीमन्त इव सागरे ।। 6.22.78 ।।  \n",
      "> \"That huge bridge was well built, magnificent, evenly built, and extensive and looked charming like the partition in a woman's hair.\"\n",
      "\n",
      "After the bridge was completed, Rama, Lakshmana, and the Vanaras, including Sugriva, crossed the ocean:\n",
      "\n",
      "> अग्रतः तस्य सैन्यस्य श्रीमान् रामः स लक्ष्मणः ।  \n",
      "> जगाम धन्वी धर्मात्मा सुग्रीवेण समन्वितः ।। 6.22.82 ।।  \n",
      "> \"Accompanied by Lakshmana and joined together with Sugriva, glorious and righteous Rama walked in front of the army.\"\n",
      "\n",
      "The Vanaras, including Hanuman, played a crucial role in this endeavor:\n",
      "\n",
      "> अयं हि विपुलो वीरः सागरो मकरालयः ।  \n",
      "> वैहायिकौ युवामेतौ वानरौ तारयिष्यतः ।। 6.22.81 ।।  \n",
      "> \"This mighty and terrific ocean, which is difficult to cross, will be crossed by you two youthful Vanaras.\"\n",
      "\n",
      "In summary, Rama and Sugriva, along with the Vanara army, crossed the ocean to reach Lanka by building a bridge, which was a remarkable feat of engineering, and then traversing it to reach the other side.\n",
      "\n",
      "---\n",
      "\n",
      "*Disclaimer: The interpretation of the scriptures may vary, and it is advisable to consult multiple sources for a comprehensive understanding.*\n"
     ]
    }
   ],
   "source": [
    "def process_for_response_gpt4(row):\n",
    "    query_str = row.Question\n",
    "    contexts = json.loads(row.used_context)\n",
    "    return get_gpt4_response(query_str, contexts)\n",
    "\n",
    "def process_for_response_trained_model(row):\n",
    "    query_str = row.Question\n",
    "    contexts = json.loads(row.used_context)\n",
    "    return get_trained_model_response(query_str, contexts)\n",
    "\n",
    "row = processed_data.iloc[54]\n",
    "# response = process_for_response_gpt4(row)\n",
    "response = process_for_response_trained_model(row)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gurukul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
