{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'projectgurukul.prompt_templates' from '/Users/krishansubudhi/repos/projectgurukul/projectgurukul/prompt_templates.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from projectgurukul import scriptures, corelib, prompt_templates\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "from llama_index.llms import ChatMessage, MessageRole\n",
    "from llama_index.prompts import ChatPromptTemplate\n",
    "from llama_index.schema import MetadataMode\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.response.notebook_utils import display_response\n",
    "# apply nested async to run in a notebook\n",
    "import nest_asyncio\n",
    "import llama_index\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from llama_index import QueryBundle\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import importlib\n",
    "importlib.reload(prompt_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Split</th>\n",
       "      <th>Scripture</th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Question Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>Why does Vasishta refuse to give Sabala to Vis...</td>\n",
       "      <td>Context 1\\nहैरण्यानां रथानां च श्वेताश्वानां च...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>Did Hanuman's devotion to Rama ever waver, eve...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>What drove Ravana to kidnap Sita, and was it s...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>Describe Bharata's character and his approach ...</td>\n",
       "      <td>Context 1\\nश्वस्तु गन्तासि तं देशं वसाद्य सह म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Train</td>\n",
       "      <td>Ramayana</td>\n",
       "      <td>From Context</td>\n",
       "      <td>How did Ravana react upon learning about Dhumr...</td>\n",
       "      <td>Context 1\\n[Ravana comes to know that Rama and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Split Scripture      Category  \\\n",
       "0   1  Train  Ramayana  From Context   \n",
       "1   2  Train  Ramayana  From Context   \n",
       "2   3  Train  Ramayana  From Context   \n",
       "3   4  Train  Ramayana  From Context   \n",
       "4   5  Train  Ramayana  From Context   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Why does Vasishta refuse to give Sabala to Vis...   \n",
       "1  Did Hanuman's devotion to Rama ever waver, eve...   \n",
       "2  What drove Ravana to kidnap Sita, and was it s...   \n",
       "3  Describe Bharata's character and his approach ...   \n",
       "4  How did Ravana react upon learning about Dhumr...   \n",
       "\n",
       "                                    Question Context  \n",
       "0  Context 1\\nहैरण्यानां रथानां च श्वेताश्वानां च...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3  Context 1\\nश्वस्तु गन्तासि तं देशं वसाद्य सह म...  \n",
       "4  Context 1\\n[Ravana comes to know that Rama and...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(\"~/Downloads/Gurukul Data - data_train.csv\").dropna(how = \"all\", axis = 1).fillna(\"\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using offline local models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishansubudhi/miniconda3/envs/gurukul/lib/python3.11/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- configuration_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ed095884a34872ad77a1a61eb4b15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi.py:   0%|          | 0.00/62.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- modeling_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b5ce9f62d94a1ca9f882403a1be403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37a75f9cae04cb8abb54b4ca23c9f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/krishansubudhi/repos/projectgurukul/training/../data//gita/.storage_instructembed/docstore.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[43mcorelib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fusion_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgita\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mramayana\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_offline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m RetrieverQueryEngine\u001b[38;5;241m.\u001b[39mfrom_args(\n\u001b[1;32m      3\u001b[0m     retriever,\n\u001b[1;32m      4\u001b[0m     text_qa_template \u001b[38;5;241m=\u001b[39m prompt_templates\u001b[38;5;241m.\u001b[39mcustom_text_qa_template)\n",
      "File \u001b[0;32m~/repos/projectgurukul/projectgurukul/corelib.py:125\u001b[0m, in \u001b[0;36mget_fusion_retriever\u001b[0;34m(scriptures, is_offline, data_dir)\u001b[0m\n\u001b[1;32m    121\u001b[0m BOOK_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscripture_info\u001b[38;5;241m.\u001b[39mDIRECTORY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m persist_dir \u001b[38;5;241m=\u001b[39m BOOK_DIR \u001b[38;5;241m+\u001b[39m storage_dir\n\u001b[1;32m    124\u001b[0m index \u001b[38;5;241m=\u001b[39m load_index_from_storage(\n\u001b[0;32m--> 125\u001b[0m     \u001b[43mStorageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_defaults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m vector_retriever \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_retriever(\n\u001b[1;32m    127\u001b[0m     similarity_top_k\u001b[38;5;241m=\u001b[39msimilarity_top_k)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# bm25_retriever = BM25Retriever.from_defaults(\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#     docstore=index.docstore, similarity_top_k=similarity_top_k\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gurukul/lib/python3.11/site-packages/llama_index/storage/storage_context.py:97\u001b[0m, in \u001b[0;36mStorageContext.from_defaults\u001b[0;34m(cls, docstore, index_store, vector_store, image_store, vector_stores, graph_store, persist_dir, fs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         vector_stores[IMAGE_VECTOR_STORE_NAMESPACE] \u001b[38;5;241m=\u001b[39m image_store\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     docstore \u001b[38;5;241m=\u001b[39m docstore \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mSimpleDocumentStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_persist_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     index_store \u001b[38;5;241m=\u001b[39m index_store \u001b[38;5;129;01mor\u001b[39;00m SimpleIndexStore\u001b[38;5;241m.\u001b[39mfrom_persist_dir(\n\u001b[1;32m    101\u001b[0m         persist_dir, fs\u001b[38;5;241m=\u001b[39mfs\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m     graph_store \u001b[38;5;241m=\u001b[39m graph_store \u001b[38;5;129;01mor\u001b[39;00m SimpleGraphStore\u001b[38;5;241m.\u001b[39mfrom_persist_dir(\n\u001b[1;32m    104\u001b[0m         persist_dir, fs\u001b[38;5;241m=\u001b[39mfs\n\u001b[1;32m    105\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/gurukul/lib/python3.11/site-packages/llama_index/storage/docstore/simple_docstore.py:56\u001b[0m, in \u001b[0;36mSimpleDocumentStore.from_persist_dir\u001b[0;34m(cls, persist_dir, namespace, fs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     persist_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(persist_dir, DEFAULT_PERSIST_FNAME)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_persist_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gurukul/lib/python3.11/site-packages/llama_index/storage/docstore/simple_docstore.py:73\u001b[0m, in \u001b[0;36mSimpleDocumentStore.from_persist_path\u001b[0;34m(cls, persist_path, namespace, fs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_persist_path\u001b[39m(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m     fs: Optional[fsspec\u001b[38;5;241m.\u001b[39mAbstractFileSystem] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     64\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimpleDocumentStore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a SimpleDocumentStore from a persist path.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     simple_kvstore \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleKVStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_persist_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(simple_kvstore, namespace)\n",
      "File \u001b[0;32m~/miniconda3/envs/gurukul/lib/python3.11/site-packages/llama_index/storage/kvstore/simple_kvstore.py:75\u001b[0m, in \u001b[0;36mSimpleKVStore.from_persist_path\u001b[0;34m(cls, persist_path, fs)\u001b[0m\n\u001b[1;32m     73\u001b[0m fs \u001b[38;5;241m=\u001b[39m fs \u001b[38;5;129;01mor\u001b[39;00m fsspec\u001b[38;5;241m.\u001b[39mfilesystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpersist_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersist_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     76\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/gurukul/lib/python3.11/site-packages/fsspec/spec.py:1295\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1295\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/miniconda3/envs/gurukul/lib/python3.11/site-packages/fsspec/implementations/local.py:180\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gurukul/lib/python3.11/site-packages/fsspec/implementations/local.py:302\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gurukul/lib/python3.11/site-packages/fsspec/implementations/local.py:307\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m--> 307\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[1;32m    309\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/krishansubudhi/repos/projectgurukul/training/../data//gita/.storage_instructembed/docstore.json'"
     ]
    }
   ],
   "source": [
    "retriever = corelib.get_fusion_retriever(['gita','ramayana'], is_offline=True, data_dir=\"../data/\")\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever,\n",
    "    text_qa_template = prompt_templates.custom_text_qa_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_service_context = ServiceContext.from_defaults(\n",
    "    llm = OpenAI(model = \"gpt-4-1106-preview\")\n",
    ")\n",
    "\n",
    "trained_model_service_context = ServiceContext.from_defaults(\n",
    "    llm = OpenAI(model = \"ft:gpt-3.5-turbo-1106:macro-mate::8jTl73oZ\")\n",
    ")\n",
    "\n",
    "query_engine_gpt_4 = RetrieverQueryEngine.from_args(\n",
    "    retriever,\n",
    "    text_qa_template = prompt_templates.custom_text_qa_template,\n",
    "    service_context=gpt4_service_context\n",
    ")\n",
    "\n",
    "query_engine_trained_model = RetrieverQueryEngine.from_args(\n",
    "    retriever,\n",
    "    text_qa_template = prompt_templates.training_text_qa_template,\n",
    "    service_context=trained_model_service_context\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import sys\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(query_str, context_str):\n",
    "    prompt = prompt_templates.custom_text_qa_template.format_messages(\n",
    "        query_str = query_str,context_str= context_str)\n",
    "    return (llama_index.llms.openai_utils.to_openai_message_dicts(prompt))\n",
    "\n",
    "def get_prompt_str(query_str, context_str):\n",
    "    prompt = prompt_templates.custom_text_qa_template.format(\n",
    "        query_str = query_str,context_str= context_str)\n",
    "    return prompt\n",
    "\n",
    "def get_contexts(context_str):\n",
    "    # Define a regex pattern to match lines with \"Context\" labels\n",
    "    pattern = re.compile(r'Context \\d+')\n",
    "\n",
    "    # Use re.sub to replace matched lines with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', context_str)\n",
    "\n",
    "    # Split the text into contexts using '---' as a separator\n",
    "    contexts = [context.strip() for context in cleaned_text.split('---')]\n",
    "    return contexts\n",
    "\n",
    "def get_response(query, contexts ):\n",
    "    response = query_engine._response_synthesizer.get_response(\n",
    "        query,\n",
    "        contexts\n",
    "    )\n",
    "    #query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "def get_response_from_row(row):\n",
    "    query_str = row.Question\n",
    "    contexts = json.loads(row.used_context)\n",
    "    return get_response(query_str, contexts)\n",
    "\n",
    "def get_gpt4_response(query, contexts ):\n",
    "    response = query_engine_gpt_4._response_synthesizer.get_response(\n",
    "        query,\n",
    "        contexts\n",
    "    )\n",
    "    #query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "def get_trained_model_response(query, contexts ):\n",
    "    response = query_engine_trained_model._response_synthesizer.get_response(\n",
    "        query,\n",
    "        contexts\n",
    "    )\n",
    "    #query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "def process_row(row):\n",
    "    new_row = pd.Series(row)\n",
    "    try:\n",
    "        query_str = row.Question\n",
    "        if row.Category == \"Outside Context\":\n",
    "            contexts = get_contexts(row[\"Question Context\"])\n",
    "        else:\n",
    "            contexts = [result.get_content(metadata_mode=MetadataMode.LLM) for result in retriever.retrieve(query_str)]\n",
    "        context_str = \"\\n\\n\".join(contexts)\n",
    "        new_row[\"used_context\"] = json.dumps(contexts, ensure_ascii=False)\n",
    "        new_row[\"prompt_str\"] = get_prompt_str(query_str, context_str)\n",
    "        new_row[\"prompt_openai\"] = json.dumps(get_prompt(query_str, context_str), ensure_ascii=False)\n",
    "        # new_row[\"answer_gpt3\"] = get_response(query_str, contexts)\n",
    "        return new_row\n",
    "    except:\n",
    "        return new_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What was rama's skin color?\"\n",
    "contexts = [result.get_content(metadata_mode=MetadataMode.LLM) for result in retriever.retrieve(query_str)]\n",
    "# for context in contexts:\n",
    "#     print(context.get_content(metadata_mode=MetadataMode.EMBED), \"\\n\\n\\n\")\n",
    "print(json.dumps(contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rama's skin color is described as being similar to the color of a blue lotus.\n",
      "\n",
      "In the Aranya Kanda, Sarga 17, Shloka 9, it is mentioned:\n",
      "> राममिन्दीवरश्यामं कन्दर्पसदृशप्रभम्।  \n",
      "> बभूवेन्द्रोपमं दृष्ट्वा राक्षसी काममोहिता।।3.17.9।।\n",
      "\n",
      "This translates to:\n",
      "> \"The demoness was infatuated with Rama, who had a blue lotus-like complexion (indīvaraśyāmaṃ), who was handsome as the god of love, and who resembled Indra.\"\n",
      "\n",
      "The term \"indīvaraśyāmaṃ\" specifically refers to the dark blue color of the blue lotus, indicating Rama's skin color.\n",
      "\n",
      "**Summary/Conclusion:**\n",
      "Rama's skin color is described as dark blue, akin to the color of a blue lotus, as stated in the Aranya Kanda of the Ramayana, Sarga 17, Shloka 9.\n",
      "\n",
      "Please note that interpretations of these descriptions may vary, and it is advisable to refer to the original texts or consult with scholars for a more comprehensive understanding.\n"
     ]
    }
   ],
   "source": [
    "response = get_gpt4_response(query_str, contexts)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed = data.progress_apply(process_row, axis = 1)\n",
    "# processed.to_csv(\"data_inferred.csv\", index=False, encoding = 'utf-8')\n",
    "# processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.read_csv(\"~/Downloads/Gurukul Data - data_labelled.csv\")\n",
    "# gpt3_responses = processed_data.iloc[10:].progress_apply(get_response_from_row, axis = 1)\n",
    "# gpt3_responses.to_frame(name='gpt3_responses').to_csv(\"gpt3_responses.csv\",encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Was Rama's decision to send Sita to the forest justified, considering the rumors about her purity?\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.iloc[53].Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rama and Sugriva, along with their army of Vanaras, crossed the ocean to reach Lanka by building a bridge with the help of the Vanara army.\n",
      "\n",
      "In the Yuddha Kanda, Sarga 22 of the Valmiki Ramayana, it is described how the Vanaras, under the leadership of Nala, constructed the bridge:\n",
      "\n",
      "> तानि कोटि सहस्राणि वानराणां महौजसाम् ।  \n",
      "> बध्नन्तः सागरे सेतुं जुग्मुः पारं महोदधेः ।। 6.22.77 ।।  \n",
      "> \"The glorious Vanaras in thousands of crores reached the other side of the sea from the bridge constructed in the great sea.\"\n",
      "\n",
      "The bridge was described as:\n",
      "\n",
      "> विशालः सुकृतश्रशीमान् सुभूमिः सुसमाहितः ।  \n",
      "> अशोभत महान् सेतुः सीमन्त इव सागरे ।। 6.22.78 ।।  \n",
      "> \"That huge bridge was well built, magnificent, evenly built, and extensive and looked charming like the partition in a woman's hair.\"\n",
      "\n",
      "After the bridge was completed, Rama, Lakshmana, and the Vanaras, including Sugriva, crossed the ocean:\n",
      "\n",
      "> अग्रतः तस्य सैन्यस्य श्रीमान् रामः स लक्ष्मणः ।  \n",
      "> जगाम धन्वी धर्मात्मा सुग्रीवेण समन्वितः ।। 6.22.82 ।।  \n",
      "> \"Accompanied by Lakshmana and joined together with Sugriva, glorious and righteous Rama walked in front of the army.\"\n",
      "\n",
      "The Vanaras, including Hanuman, played a crucial role in this endeavor:\n",
      "\n",
      "> अयं हि विपुलो वीरः सागरो मकरालयः ।  \n",
      "> वैहायिकौ युवामेतौ वानरौ तारयिष्यतः ।। 6.22.81 ।।  \n",
      "> \"This mighty and terrific ocean, which is difficult to cross, will be crossed by you two youthful Vanaras.\"\n",
      "\n",
      "In summary, Rama and Sugriva, along with the Vanara army, crossed the ocean to reach Lanka by building a bridge, which was a remarkable feat of engineering, and then traversing it to reach the other side.\n",
      "\n",
      "---\n",
      "\n",
      "*Disclaimer: The interpretation of the scriptures may vary, and it is advisable to consult multiple sources for a comprehensive understanding.*\n"
     ]
    }
   ],
   "source": [
    "def process_for_response_gpt4(row):\n",
    "    query_str = row.Question\n",
    "    contexts = json.loads(row.used_context)\n",
    "    return get_gpt4_response(query_str, contexts)\n",
    "\n",
    "def process_for_response_trained_model(row):\n",
    "    query_str = row.Question\n",
    "    contexts = json.loads(row.used_context)\n",
    "    return get_trained_model_response(query_str, contexts)\n",
    "\n",
    "row = processed_data.iloc[54]\n",
    "# response = process_for_response_gpt4(row)\n",
    "response = process_for_response_trained_model(row)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gurukul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
